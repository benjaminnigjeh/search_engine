{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf133feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unconditional diffusion model on MS2 spectra in combined_annotated.h5\n",
    "\n",
    "- Trains DDPM on ms2_lib (shape: [N, 1600]) from your H5 file\n",
    "- Generates synthetic spectra and saves:\n",
    "    synthetic_ms2.npy      (num_samples, 1600)\n",
    "    synthetic_ms2.png      (plot of a few sampled spectra)\n",
    "- Saves loss curves each epoch: loss_curve_epochX.png\n",
    "- Verbose training logs so you can watch progress\n",
    "\n",
    "Requires:\n",
    "    pip install torch torchvision h5py numpy matplotlib\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# USER SETTINGS\n",
    "# =========================\n",
    "H5_PATH       = r\"F:\\20251115\\spectra_h5\\combined_annotated.h5\"\n",
    "H5_DATASET    = \"ms2_lib\"       # change if your dataset name is different\n",
    "OUT_DIR       = r\"F:\\20251115\\spectra_h5\\diffusion_out\"\n",
    "\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "BATCH_SIZE    = 256\n",
    "NUM_EPOCHS    = 10              # start small; increase when things look good\n",
    "LR            = 2e-4\n",
    "NUM_TIMESTEPS = 10           # diffusion steps (T)\n",
    "SPECTRUM_LEN  = 1600            # length of each MS2 vector\n",
    "\n",
    "NUM_SAMPLES   = 32              # how many synthetic spectra to generate\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# DATASET\n",
    "# =========================\n",
    "\n",
    "class MS2H5Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Lazily reads spectra from an H5 file: [N, SPECTRUM_LEN]\n",
    "    Scaling:\n",
    "        - per-spectrum divide by max (if >0) -> [0,1]\n",
    "        - then map to [-1, 1] for diffusion\n",
    "    \"\"\"\n",
    "    def __init__(self, h5_path, dataset_name):\n",
    "        super().__init__()\n",
    "        self.h5_path = h5_path\n",
    "        self.dataset_name = dataset_name\n",
    "        self.h5 = h5py.File(self.h5_path, \"r\")\n",
    "        self.ds = self.h5[self.dataset_name]\n",
    "        self.length = self.ds.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.ds[idx].astype(np.float32)  # shape (SPECTRUM_LEN,)\n",
    "        # per-spectrum max scaling\n",
    "        m = x.max()\n",
    "        if m > 0:\n",
    "            x = x / m\n",
    "        # map [0,1] -> [-1,1]\n",
    "        x = x * 2.0 - 1.0\n",
    "        return torch.from_numpy(x)\n",
    "\n",
    "    def close(self):\n",
    "        if self.h5 is not None:\n",
    "            self.h5.close()\n",
    "            self.h5 = None\n",
    "\n",
    "# =========================\n",
    "# DIFFUSION UTILITIES\n",
    "# =========================\n",
    "\n",
    "def make_beta_schedule(T, beta_start=1e-4, beta_end=2e-2):\n",
    "    return torch.linspace(beta_start, beta_end, T)\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, T, device):\n",
    "        self.T = T\n",
    "        self.device = device\n",
    "\n",
    "        betas = make_beta_schedule(T).to(device)          # (T,)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "        self.betas = betas\n",
    "        self.alphas = alphas\n",
    "        self.alphas_cumprod = alphas_cumprod\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "            [torch.tensor([1.0], device=device), alphas_cumprod[:-1]], dim=0\n",
    "        )\n",
    "\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
    "        self.sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "        self.sqrt_recipm1_alphas = torch.sqrt(1.0 / alphas - 1.0)\n",
    "\n",
    "        # posterior variance\n",
    "        self.posterior_var = betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "\n",
    "    def q_sample(self, x0, t, noise=None):\n",
    "        \"\"\"\n",
    "        Forward diffusion: sample x_t from x_0 at time t\n",
    "        x0: (B, D)\n",
    "        t:  (B,) integer timesteps in [0, T-1]\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t].view(-1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1)\n",
    "        return sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "\n",
    "    def p_sample(self, model, x_t, t):\n",
    "        \"\"\"\n",
    "        One reverse step p(x_{t-1} | x_t)\n",
    "        \"\"\"\n",
    "        betas_t = self.betas[t].view(-1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1)\n",
    "        sqrt_recip_alphas_t = self.sqrt_recip_alphas[t].view(-1, 1)\n",
    "\n",
    "        # model predicts epsilon\n",
    "        eps_theta = model(x_t, t)\n",
    "\n",
    "        # x0_estimate from predicted noise\n",
    "        x0_hat = sqrt_recip_alphas_t * (x_t - betas_t / sqrt_one_minus_alphas_cumprod_t * eps_theta)\n",
    "\n",
    "        # posterior mean μ_t\n",
    "        alphas_t = self.alphas[t].view(-1, 1)\n",
    "        alphas_cumprod_t = self.alphas_cumprod[t].view(-1, 1)\n",
    "        alphas_cumprod_prev_t = self.alphas_cumprod_prev[t].view(-1, 1)\n",
    "\n",
    "        posterior_mean = (\n",
    "            betas_t * torch.sqrt(alphas_cumprod_prev_t) / (1.0 - alphas_cumprod_t) * x0_hat\n",
    "            + (torch.sqrt(alphas_t) * (1.0 - alphas_cumprod_prev_t) / (1.0 - alphas_cumprod_t)) * x_t\n",
    "        )\n",
    "\n",
    "        posterior_var_t = self.posterior_var[t].view(-1, 1)\n",
    "        if (t == 0).all():\n",
    "            # no noise at final step\n",
    "            return posterior_mean\n",
    "\n",
    "        noise = torch.randn_like(x_t)\n",
    "        return posterior_mean + torch.sqrt(posterior_var_t) * noise\n",
    "\n",
    "    def p_sample_loop(self, model, shape):\n",
    "        \"\"\"\n",
    "        Sample from pure noise x_T ~ N(0, I), then reverse to x_0.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        x_t = torch.randn(shape, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            for time_step in reversed(range(self.T)):\n",
    "                t_tensor = torch.full((shape[0],), time_step, device=self.device, dtype=torch.long)\n",
    "                x_t = self.p_sample(model, x_t, t_tensor)\n",
    "        return x_t\n",
    "\n",
    "# =========================\n",
    "# TIME EMBEDDING + MODEL\n",
    "# =========================\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Classic transformer-style sinusoidal embedding of timestep t.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        t: (B,) integer timesteps\n",
    "        returns: (B, dim)\n",
    "        \"\"\"\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t.float().unsqueeze(1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        return emb\n",
    "\n",
    "class DenoiseMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP epsilon-predictor with time conditioning.\n",
    "    Input:  x_t (B, D), t (B,)\n",
    "    Output: eps_theta (B, D)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dim, time_dim=256, hidden_dim=1024, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalTimeEmbedding(time_dim),\n",
    "            nn.Linear(time_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        input_dim = data_dim + hidden_dim\n",
    "        for i in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(input_dim if i == 0 else hidden_dim, hidden_dim))\n",
    "            layers.append(nn.SiLU())\n",
    "        layers.append(nn.Linear(hidden_dim, data_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # x: (B, D), t: (B,)\n",
    "        t_emb = self.time_mlp(t)      # (B, hidden_dim)\n",
    "        # concatenate time embedding with spectrum\n",
    "        x_in = torch.cat([x, t_emb], dim=1)\n",
    "        return self.net(x_in)\n",
    "\n",
    "# =========================\n",
    "# TRAINING (HIGH VERBOSITY)\n",
    "# =========================\n",
    "\n",
    "def train():\n",
    "    dataset = MS2H5Dataset(H5_PATH, H5_DATASET)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,   # keep 0 for h5py safety\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    model = DenoiseMLP(SPECTRUM_LEN).to(DEVICE)\n",
    "    diffusion = Diffusion(NUM_TIMESTEPS, DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "    loss_log = []     # store loss for plotting\n",
    "    global_step = 0\n",
    "\n",
    "    print(\"\\n========== START TRAINING ==========\\n\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total spectra: {len(dataset):,}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Steps per epoch: {len(dataloader)}\")\n",
    "    print(f\"Timesteps (T): {NUM_TIMESTEPS}\")\n",
    "    print(\"--------------------------------------\\n\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\n===== Epoch {epoch+1}/{NUM_EPOCHS} =====\")\n",
    "        epoch_loss = []\n",
    "\n",
    "        for batch_i, batch in enumerate(dataloader):\n",
    "            batch = batch.to(DEVICE)\n",
    "\n",
    "            t = torch.randint(\n",
    "                0, NUM_TIMESTEPS,\n",
    "                (batch.size(0),),\n",
    "                device=DEVICE\n",
    "            ).long()\n",
    "\n",
    "            noise = torch.randn_like(batch)\n",
    "            x_t = diffusion.q_sample(batch, t, noise)\n",
    "            eps_pred = model(x_t, t)\n",
    "\n",
    "            loss = nn.functional.mse_loss(eps_pred, noise)\n",
    "            epoch_loss.append(loss.item())\n",
    "            loss_log.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            # ---- VERBOSITY: Every 50 steps ----\n",
    "            if global_step % 50 == 0:\n",
    "                print(f\"[Epoch {epoch+1} | Step {batch_i+1}/{len(dataloader)} | \"\n",
    "                      f\"Global {global_step}] Loss: {loss.item():.6f}\")\n",
    "\n",
    "            # ---- Extra: Every 250 steps ----\n",
    "            if global_step % 250 == 0:\n",
    "                avg_last_250 = np.mean(loss_log[-250:])\n",
    "                print(f\"    ↳ Rolling avg (last 250 steps): {avg_last_250:.6f}\")\n",
    "\n",
    "        # ---- End of epoch summary ----\n",
    "        mean_epoch_loss = np.mean(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1} done. Mean loss: {mean_epoch_loss:.6f}\")\n",
    "\n",
    "        # ---- Save checkpoint ----\n",
    "        ckpt_path = os.path.join(OUT_DIR, f\"diffusion_epoch{epoch+1}.pt\")\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"epoch\": epoch + 1,\n",
    "        }, ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # ---- Save loss plot each epoch ----\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(loss_log, alpha=0.8)\n",
    "        plt.xlabel(\"Training step\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Diffusion Training Loss\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"loss_curve_epoch{epoch+1}.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        print(\"Saved loss plot\")\n",
    "\n",
    "    dataset.close()\n",
    "    return model, diffusion, loss_log\n",
    "\n",
    "# =========================\n",
    "# SAMPLING & SAVING\n",
    "# =========================\n",
    "\n",
    "def sample_and_save(model, diffusion, num_samples=NUM_SAMPLES):\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    samples = diffusion.p_sample_loop(\n",
    "        model,\n",
    "        shape=(num_samples, SPECTRUM_LEN)\n",
    "    )  # in [-1,1]\n",
    "\n",
    "    # map back to [0,1]\n",
    "    samples = (samples.clamp(-1, 1) + 1.0) / 2.0\n",
    "    samples = samples.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # optionally renormalize each spectrum so its max=1\n",
    "    max_vals = samples.max(axis=1, keepdims=True)\n",
    "    max_vals[max_vals == 0] = 1.0\n",
    "    samples = samples / max_vals\n",
    "\n",
    "    out_npy = os.path.join(OUT_DIR, \"synthetic_ms2.npy\")\n",
    "    np.save(out_npy, samples)\n",
    "    print(f\"Saved synthetic spectra to: {out_npy}\")\n",
    "\n",
    "    # quick visualization of first few spectra\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(min(5, num_samples)):\n",
    "        plt.plot(samples[i], alpha=0.7)\n",
    "    plt.xlabel(\"m/z bin index\")\n",
    "    plt.ylabel(\"normalized intensity\")\n",
    "    plt.title(\"Synthetic MS2 spectra from diffusion model\")\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(OUT_DIR, \"synthetic_ms2.png\")\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"Saved plot: {out_png}\")\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, diffusion, loss_log = train()\n",
    "    sample_and_save(model, diffusion, NUM_SAMPLES)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
