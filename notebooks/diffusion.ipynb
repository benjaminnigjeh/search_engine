{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf133feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H5 path: F:\\20251115\\spectra_h5\\combined_annotated.h5\n",
      "Output dir: F:\\20251130\\diffusion_out\n",
      "Device: cpu | USE_AMP: False\n",
      "Loaded dataset 'ms2_lib' from H5.\n",
      "Full shape: (2202567, 1600)\n",
      "Randomly selected 5120 spectra for training.\n",
      "\n",
      "========== START TRAINING ==========\n",
      "\n",
      "Device: cpu\n",
      "Total spectra in file: 2,202,567\n",
      "Using spectra for training: 5,120\n",
      "Batch size: 256\n",
      "Steps per epoch: 20\n",
      "Timesteps (T): 10\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "===== Epoch 1/10 =====\n",
      "[Epoch 1] Batch 1/20 | global step 0\n",
      "Epoch 1 done. Mean loss: 0.068497\n",
      "\n",
      "===== Epoch 2/10 =====\n",
      "[Epoch 2] Batch 1/20 | global step 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 465\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved synthetic plot to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_png)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# 8) Run training + sampling\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m model, diffusion, loss_log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m sample_and_save(model, diffusion, NUM_SAMPLES)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll done. Outputs saved in:\u001b[39m\u001b[38;5;124m\"\u001b[39m, OUT_DIR)\n",
      "Cell \u001b[1;32mIn[1], line 387\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    385\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    390\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\benja\\miniconda3\\envs\\vae\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    624\u001b[0m     )\n\u001b[1;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\benja\\miniconda3\\envs\\vae\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\benja\\miniconda3\\envs\\vae\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1) Imports & paths  (LOCAL NOTEBOOK VERSION)\n",
    "# ============================================\n",
    "import os\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modern AMP API (PyTorch >= 2.0)\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# ---------- EDIT THIS PART ----------\n",
    "# Full path to your local H5 databank:\n",
    "H5_PATH     = r\"F:\\20251115\\spectra_h5\\combined_annotated.h5\"   # <-- change this\n",
    "H5_DATASET  = \"ms2_lib\"                                        # dataset name in H5\n",
    "\n",
    "# Where to save outputs (check this exists or will be created):\n",
    "OUT_DIR     = r\"F:\\20251130\\diffusion_out\"                     # <-- change if you want\n",
    "\n",
    "# -----------------------------------\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "USE_AMP       = (DEVICE == \"cuda\")\n",
    "USE_TORCH_COMPILE = False   # turn ON for long runs, OFF for quick tests\n",
    "\n",
    "BATCH_SIZE    = 256         # UNet is heavier than MLP; tweak if OOM\n",
    "NUM_EPOCHS    = 10          # increase for better quality (e.g. 30+)\n",
    "LR            = 2e-4\n",
    "NUM_TIMESTEPS = 10          # can increase later to 50–100\n",
    "SPECTRUM_LEN  = 1600        # bins from 400–2000 m/z (1 amu)\n",
    "\n",
    "NUM_SAMPLES       = 32      # how many synthetic spectra to generate\n",
    "MAX_TRAIN_SPECTRA = 5120    # randomly choose this many from H5 (None = all)\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"H5 path:\", H5_PATH)\n",
    "print(\"Output dir:\", OUT_DIR)\n",
    "print(\"Device:\", DEVICE, \"| USE_AMP:\", USE_AMP)\n",
    "\n",
    "# ============================================\n",
    "# 3) Dataset (RANDOM SUBSET + improved normalization)\n",
    "# ============================================\n",
    "class MS2H5Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Lazily reads spectra from local H5 and returns normalized 1D spectra.\n",
    "    Normalization:\n",
    "      - per-spectrum TIC: x = x / sum(x)\n",
    "      - sqrt compression: x = sqrt(x)\n",
    "      - map [0,1] -> [-1,1] for diffusion\n",
    "    \"\"\"\n",
    "    def __init__(self, h5_path, dataset_name, max_spectra=None, seed=42):\n",
    "        super().__init__()\n",
    "        self.h5_path = h5_path\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        self.h5 = h5py.File(self.h5_path, \"r\")\n",
    "        self.ds = self.h5[self.dataset_name]\n",
    "        full_len = self.ds.shape[0]\n",
    "\n",
    "        if (max_spectra is None) or (max_spectra >= full_len):\n",
    "            self.indices = np.arange(full_len)\n",
    "        else:\n",
    "            rng = np.random.default_rng(seed=seed)\n",
    "            self.indices = rng.choice(full_len, size=max_spectra, replace=False)\n",
    "\n",
    "        self.length = len(self.indices)\n",
    "\n",
    "        print(f\"Loaded dataset '{dataset_name}' from H5.\")\n",
    "        print(\"Full shape:\", self.ds.shape)\n",
    "        print(f\"Randomly selected {self.length} spectra for training.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        x = self.ds[real_idx].astype(np.float32)   # (SPECTRUM_LEN,)\n",
    "\n",
    "        # TIC normalization\n",
    "        tic = x.sum()\n",
    "        if tic > 0:\n",
    "            x = x / tic\n",
    "\n",
    "        # sqrt compression (better dynamic range)\n",
    "        x = np.sqrt(x)\n",
    "\n",
    "        # map [0,1] -> [-1,1]\n",
    "        x = x * 2.0 - 1.0\n",
    "\n",
    "        return torch.from_numpy(x)\n",
    "\n",
    "    def close(self):\n",
    "        if self.h5 is not None:\n",
    "            self.h5.close()\n",
    "            self.h5 = None\n",
    "\n",
    "# ============================================\n",
    "# 4) Diffusion utils (x0-prediction)\n",
    "# ============================================\n",
    "def make_beta_schedule(T, beta_start=1e-4, beta_end=2e-2):\n",
    "    return torch.linspace(beta_start, beta_end, T)\n",
    "\n",
    "class Diffusion:\n",
    "    \"\"\"\n",
    "    Standard DDPM with model predicting x0 (clean spectrum).\n",
    "    \"\"\"\n",
    "    def __init__(self, T, device):\n",
    "        self.T = T\n",
    "        self.device = device\n",
    "\n",
    "        betas = make_beta_schedule(T).to(device)   # (T,)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "        self.betas = betas\n",
    "        self.alphas = alphas\n",
    "        self.alphas_cumprod = alphas_cumprod\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "            [torch.tensor([1.0], device=device), alphas_cumprod[:-1]], dim=0\n",
    "        )\n",
    "\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
    "        self.sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "        self.posterior_var = betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "\n",
    "    def q_sample(self, x0, t, noise=None):\n",
    "        \"\"\"\n",
    "        Forward diffusion q(x_t | x_0)\n",
    "        x0: (B, D) in [-1,1]\n",
    "        t:  (B,) int in [0,T-1]\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t].view(-1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1)\n",
    "        return sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "\n",
    "    def p_sample(self, model, x_t, t):\n",
    "        \"\"\"\n",
    "        One reverse step p(x_{t-1} | x_t) using model that predicts x0.\n",
    "        \"\"\"\n",
    "        betas_t = self.betas[t].view(-1, 1)\n",
    "        alphas_t = self.alphas[t].view(-1, 1)\n",
    "        alphas_cumprod_t = self.alphas_cumprod[t].view(-1, 1)\n",
    "        alphas_cumprod_prev_t = self.alphas_cumprod_prev[t].view(-1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1)\n",
    "\n",
    "        # model predicts x0 directly\n",
    "        x0_pred = model(x_t, t).clamp(-1.0, 1.0)\n",
    "\n",
    "        # posterior mean μ_t\n",
    "        posterior_mean = (\n",
    "            betas_t * torch.sqrt(alphas_cumprod_prev_t) / (1.0 - alphas_cumprod_t) * x0_pred\n",
    "            + (torch.sqrt(alphas_t) * (1.0 - alphas_cumprod_prev_t) / (1.0 - alphas_cumprod_t)) * x_t\n",
    "        )\n",
    "\n",
    "        posterior_var_t = self.posterior_var[t].view(-1, 1)\n",
    "        if (t == 0).all():\n",
    "            return posterior_mean\n",
    "\n",
    "        noise = torch.randn_like(x_t)\n",
    "        return posterior_mean + torch.sqrt(posterior_var_t) * noise\n",
    "\n",
    "    def p_sample_loop(self, model, shape):\n",
    "        \"\"\"\n",
    "        Draw x_T ~ N(0,I) and iteratively sample to x_0.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        x_t = torch.randn(shape, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            for time_step in reversed(range(self.T)):\n",
    "                t_tensor = torch.full((shape[0],), time_step, device=self.device, dtype=torch.long)\n",
    "                x_t = self.p_sample(model, x_t, t_tensor)\n",
    "        return x_t\n",
    "\n",
    "# ============================================\n",
    "# 5) Time embedding + UNet-1D model\n",
    "# ============================================\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        t: (B,) integer timesteps\n",
    "        returns: (B, dim)\n",
    "        \"\"\"\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t.float().unsqueeze(1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        return emb\n",
    "\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_dim, kernel_size=3, groups=8):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, padding=padding)\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, padding=padding)\n",
    "        self.norm1 = nn.GroupNorm(groups, out_ch)\n",
    "        self.norm2 = nn.GroupNorm(groups, out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "        self.time_proj = nn.Linear(time_dim, out_ch)\n",
    "        self.skip = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        \"\"\"\n",
    "        x: (B, C, L)\n",
    "        t_emb: (B, time_dim)\n",
    "        \"\"\"\n",
    "        h = self.conv1(x)\n",
    "        # add time embedding\n",
    "        t = self.time_proj(t_emb).unsqueeze(-1)   # (B, out_ch, 1)\n",
    "        h = h + t\n",
    "        h = self.act(self.norm1(h))\n",
    "\n",
    "        h = self.conv2(h)\n",
    "        h = self.act(self.norm2(h))\n",
    "\n",
    "        return h + self.skip(x)\n",
    "\n",
    "class UNet1D(nn.Module):\n",
    "    \"\"\"\n",
    "    1D U-Net for spectra with time conditioning.\n",
    "    Input:  x_t (B, D), t (B,)\n",
    "    Output: x0_pred (B, D)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dim, time_dim=128, base_ch=64):\n",
    "        super().__init__()\n",
    "        self.data_dim = data_dim\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalTimeEmbedding(time_dim),\n",
    "            nn.Linear(time_dim, time_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim * 4, time_dim),\n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        self.in_conv = nn.Conv1d(1, base_ch, 3, padding=1)\n",
    "        self.enc1 = ResBlock1D(base_ch,   base_ch,   time_dim)\n",
    "        self.down1 = nn.Conv1d(base_ch,   base_ch*2, 4, stride=2, padding=1)\n",
    "\n",
    "        self.enc2 = ResBlock1D(base_ch*2, base_ch*2, time_dim)\n",
    "        self.down2 = nn.Conv1d(base_ch*2, base_ch*4, 4, stride=2, padding=1)\n",
    "\n",
    "        self.enc3 = ResBlock1D(base_ch*4, base_ch*4, time_dim)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.mid = ResBlock1D(base_ch*4, base_ch*4, time_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.up2 = nn.ConvTranspose1d(base_ch*4, base_ch*2, 4, stride=2, padding=1)\n",
    "        self.dec2 = ResBlock1D(base_ch*4, base_ch*2, time_dim)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose1d(base_ch*2, base_ch, 4, stride=2, padding=1)\n",
    "        self.dec1 = ResBlock1D(base_ch*2, base_ch, time_dim)\n",
    "\n",
    "        self.out_conv = nn.Conv1d(base_ch, 1, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        x: (B, D) in [-1,1]\n",
    "        t: (B,) timesteps\n",
    "        \"\"\"\n",
    "        # prepare shapes\n",
    "        x = x.unsqueeze(1)   # (B,1,L)\n",
    "        t_emb = self.time_mlp(t)  # (B, time_dim)\n",
    "\n",
    "        # Encoder\n",
    "        x0 = self.in_conv(x)\n",
    "        e1 = self.enc1(x0, t_emb)\n",
    "        d1 = self.down1(e1)\n",
    "\n",
    "        e2 = self.enc2(d1, t_emb)\n",
    "        d2 = self.down2(e2)\n",
    "\n",
    "        e3 = self.enc3(d2, t_emb)\n",
    "\n",
    "        # Bottleneck\n",
    "        m = self.mid(e3, t_emb)\n",
    "\n",
    "        # Decoder\n",
    "        u2 = self.up2(m)\n",
    "        u2 = torch.cat([u2, e2], dim=1)\n",
    "        d2 = self.dec2(u2, t_emb)\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        u1 = torch.cat([u1, e1], dim=1)\n",
    "        d1 = self.dec1(u1, t_emb)\n",
    "\n",
    "        out = self.out_conv(d1)      # (B,1,L)\n",
    "        out = out.squeeze(1)         # (B,L)\n",
    "        return out\n",
    "\n",
    "# ============================================\n",
    "# 6) Training (UNet + x0 prediction)\n",
    "# ============================================\n",
    "def train():\n",
    "    dataset = MS2H5Dataset(\n",
    "        H5_PATH,\n",
    "        H5_DATASET,\n",
    "        max_spectra=MAX_TRAIN_SPECTRA,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=(DEVICE == \"cuda\"),\n",
    "    )\n",
    "\n",
    "    model = UNet1D(SPECTRUM_LEN).to(DEVICE)\n",
    "\n",
    "    if USE_TORCH_COMPILE:\n",
    "        try:\n",
    "            model = torch.compile(model)\n",
    "            print(\"Using torch.compile for model.\")\n",
    "        except Exception as e:\n",
    "            print(\"torch.compile not used:\", e)\n",
    "\n",
    "    diffusion = Diffusion(NUM_TIMESTEPS, DEVICE)\n",
    "    scaler = GradScaler(device=\"cuda\", enabled=USE_AMP)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "    loss_log = []\n",
    "    global_step = 0\n",
    "\n",
    "    print(\"\\n========== START TRAINING ==========\\n\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total spectra in file: {dataset.ds.shape[0]:,}\")\n",
    "    print(f\"Using spectra for training: {len(dataset):,}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Steps per epoch: {len(dataloader)}\")\n",
    "    print(f\"Timesteps (T): {NUM_TIMESTEPS}\")\n",
    "    print(\"--------------------------------------\\n\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\n===== Epoch {epoch+1}/{NUM_EPOCHS} =====\")\n",
    "        epoch_loss = []\n",
    "\n",
    "        for batch_i, batch in enumerate(dataloader):\n",
    "            batch = batch.to(DEVICE, non_blocking=True)   # x0 in [-1,1]\n",
    "\n",
    "            if batch_i == 0 or (batch_i + 1) % 50 == 0:\n",
    "                print(f\"[Epoch {epoch+1}] Batch {batch_i+1}/{len(dataloader)} \"\n",
    "                      f\"| global step {global_step}\")\n",
    "\n",
    "            # sample random timesteps\n",
    "            t = torch.randint(\n",
    "                0, NUM_TIMESTEPS,\n",
    "                (batch.size(0),),\n",
    "                device=DEVICE\n",
    "            ).long()\n",
    "\n",
    "            # forward diffusion\n",
    "            noise = torch.randn_like(batch)\n",
    "            with autocast(device_type=\"cuda\", enabled=USE_AMP):\n",
    "                x_t = diffusion.q_sample(batch, t, noise)\n",
    "                x0_pred = model(x_t, t)\n",
    "                loss = nn.functional.mse_loss(x0_pred, batch)\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            loss_log.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if USE_AMP:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % 200 == 0:\n",
    "                print(f\"[Epoch {epoch+1} | Step {batch_i+1}/{len(dataloader)} \"\n",
    "                      f\"| Global {global_step}] Loss: {loss.item():.6f}\")\n",
    "\n",
    "        mean_epoch_loss = float(np.mean(epoch_loss))\n",
    "        print(f\"Epoch {epoch+1} done. Mean loss: {mean_epoch_loss:.6f}\")\n",
    "\n",
    "    # Save final checkpoint\n",
    "    ckpt_path = os.path.join(OUT_DIR, \"diffusion_unet_final.pt\")\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"epoch\": NUM_EPOCHS,\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved final checkpoint: {ckpt_path}\")\n",
    "\n",
    "    # Loss curve\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(loss_log, alpha=0.8)\n",
    "    plt.xlabel(\"Training step\")\n",
    "    plt.ylabel(\"MSE loss (x0 prediction)\")\n",
    "    plt.title(\"Diffusion Training Loss (UNet-1D)\")\n",
    "    plt.tight_layout()\n",
    "    loss_plot_path = os.path.join(OUT_DIR, \"loss_curve_unet.png\")\n",
    "    plt.savefig(loss_plot_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(\"Saved loss plot to:\", loss_plot_path)\n",
    "\n",
    "    dataset.close()\n",
    "    return model, diffusion, loss_log\n",
    "\n",
    "# ============================================\n",
    "# 7) Sampling + saving outputs\n",
    "# ============================================\n",
    "def sample_and_save(model, diffusion, num_samples=NUM_SAMPLES):\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    # generate in [-1,1]\n",
    "    samples = diffusion.p_sample_loop(\n",
    "        model,\n",
    "        shape=(num_samples, SPECTRUM_LEN)\n",
    "    )\n",
    "\n",
    "    # map [-1,1] -> [0,1]\n",
    "    samples = (samples.clamp(-1, 1) + 1.0) / 2.0\n",
    "    samples = samples.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # optional: renormalize each spectrum to max=1\n",
    "    max_vals = samples.max(axis=1, keepdims=True)\n",
    "    max_vals[max_vals == 0] = 1.0\n",
    "    samples = samples / max_vals\n",
    "\n",
    "    out_npy = os.path.join(OUT_DIR, \"synthetic_ms2.npy\")\n",
    "    np.save(out_npy, samples)\n",
    "    print(\"Saved synthetic spectra to:\", out_npy)\n",
    "\n",
    "    # quick visualization (overlay 5)\n",
    "    mz_axis = np.linspace(400, 2000, SPECTRUM_LEN, endpoint=False)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(min(5, num_samples)):\n",
    "        plt.plot(mz_axis, samples[i], alpha=0.7)\n",
    "    plt.xlabel(\"m/z\")\n",
    "    plt.ylabel(\"normalized intensity\")\n",
    "    plt.title(\"Synthetic MS2 spectra from UNet diffusion\")\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(OUT_DIR, \"synthetic_ms2_unet.png\")\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(\"Saved synthetic plot to:\", out_png)\n",
    "\n",
    "# ============================================\n",
    "# 8) Run training + sampling\n",
    "# ============================================\n",
    "model, diffusion, loss_log = train()\n",
    "sample_and_save(model, diffusion, NUM_SAMPLES)\n",
    "print(\"All done. Outputs saved in:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
